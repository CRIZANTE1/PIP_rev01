import streamlit as st
import pandas as pd
import numpy as np
import google.generativeai as genai

from AI.api_load import load_api
from gdrive.gdrive_upload import GoogleDriveUploader

RAG_SHEET_NAME = "RAG_PIP"
EMBEDDING_MODEL = 'text-embedding-004'

class RAGAnalyzer:
    def __init__(self):
        load_api()
        self.model = genai.GenerativeModel('gemini-1.5-pro-latest')
        self.knowledge_base_df = self._load_and_embed_knowledge_base()

    @st.cache_data(ttl=3600)  # Cache por 1 hora para evitar recarregar e re-embedar constantemente
    def _load_and_embed_knowledge_base(_self):
        """
        Carrega a base de conhecimento da planilha Google, cria um documento sint√©tico
        para cada linha e gera os embeddings em tempo real.
        Os resultados s√£o armazenados em cache para performance.
        """
        try:
            # 1. Carregar dados do Google Sheets
            uploader = GoogleDriveUploader()
            st.info(f"Carregando e processando a base de conhecimento '{RAG_SHEET_NAME}'...")
            data = uploader.get_data_from_sheet(RAG_SHEET_NAME)
            
            if not data or len(data) < 2:
                st.warning(f"A base de conhecimento '{RAG_SHEET_NAME}' est√° vazia ou n√£o foi encontrada.")
                return pd.DataFrame()

            headers = data[0]
            df = pd.DataFrame(data[1:], columns=headers)
            
            # 2. Criar o documento sint√©tico para embedding
            # Combinamos as colunas mais ricas em texto para criar um super-documento.
            # Isso cria um vetor que representa o conceito completo daquela linha.
            required_cols = ['Keywords', 'Question', 'Answer_Chunk']
            if not all(col in df.columns for col in required_cols):
                 st.error(f"A base de conhecimento est√° mal formatada. Faltam as colunas: {', '.join(col for col in required_cols if col not in df.columns)}")
                 return pd.DataFrame()
            
            df['synthetic_document'] = (
                "Palavras-chave: " + df['Keywords'].fillna('') + "; " +
                "Pergunta Relevante: " + df['Question'].fillna('') + "; " +
                "Diretriz ou Resposta: " + df['Answer_Chunk'].fillna('')
            )
            
            texts_to_embed = df['synthetic_document'].tolist()
            
            # 3. Gerar Embeddings em tempo real
            st.info(f"Gerando embeddings para {len(df)} normas...")
            result = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=texts_to_embed,
                task_type="RETRIEVAL_DOCUMENT",
                title="Normas de Seguran√ßa para I√ßamento de Carga"
            )
            df['embedding'] = result['embedding']
            st.success("Base de conhecimento pronta para uso.")
            return df
        
        except Exception as e:
            st.error(f"Falha ao carregar e processar a base de conhecimento: {e}")
            return pd.DataFrame()

    def _find_best_passages(self, query: str, top_k=3) -> pd.DataFrame:
        """Encontra os trechos mais relevantes no DataFrame usando similaridade de embeddings."""
        if self.knowledge_base_df.empty or 'embedding' not in self.knowledge_base_df.columns:
            return pd.DataFrame()

        # 1. Gera o embedding para a consulta (o problema)
        query_embedding = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=query,
            task_type="RETRIEVAL_QUERY"
        )['embedding']
        
        # 2. Calcula a similaridade (produto escalar)
        dot_products = np.dot(np.stack(self.knowledge_base_df['embedding']), query_embedding)
        
        # 3. Pega os √≠ndices dos 'top_k' melhores resultados
        indices = np.argsort(dot_products)[-top_k:][::-1]
        
        return self.knowledge_base_df.iloc[indices]

    def _retrieve_context(self, issues: list) -> str:
        """
        Busca na base de conhecimento os trechos mais relevantes para os problemas identificados
        usando a busca por similaridade de vetores.
        """
        if self.knowledge_base_df.empty:
            return "A base de conhecimento normativo n√£o est√° dispon√≠vel."
        
        # Concatena todos os problemas em uma √∫nica consulta
        full_query = ". ".join(issues).replace("_", " ") # Transforma 'cnh_vencida' em 'cnh vencida'
        
        context_str = "Contexto Normativo Relevante Encontrado:\n\n"
        
        relevant_df = self._find_best_passages(full_query)
        
        if relevant_df.empty:
            return "Nenhuma norma espec√≠fica encontrada na base de conhecimento para os pontos de aten√ß√£o desta opera√ß√£o."
        
        for _, row in relevant_df.iterrows():
            # Agora podemos incluir todas as informa√ß√µes que quisermos no contexto
            context_str += f"**Refer√™ncia:** {row.get('Norma_Referencia', 'N/A')} (Se√ß√£o: {row.get('Section_Number', 'N/A')})\n"
            context_str += f"**Pergunta Chave:** {row.get('Question', 'N/A')}\n"
            context_str += f"**Diretriz:** {row.get('Answer_Chunk', 'N/A')}\n"
            context_str += "---\n"
            
        return context_str

    def generate_final_analysis(self, operation_summary: str, issues: list) -> str:
        """Gera a an√°lise final (o prompt permanece o mesmo, mas agora recebe um contexto mais rico)."""
        
        if not issues:
             return "### ‚úÖ Parecer Final: APROVADO\n\nNenhum ponto de aten√ß√£o cr√≠tico foi identificado nos dados fornecidos. A opera√ß√£o parece estar em conformidade com os par√¢metros b√°sicos de seguran√ßa e documenta√ß√£o."

        normative_context = self._retrieve_context(issues)
        
        # O prompt permanece o mesmo, pois √© robusto e gen√©rico
        prompt = f"""
        **Persona:** Voc√™ √© um Engenheiro de Seguran√ßa do Trabalho altamente experiente, especialista em opera√ß√µes de i√ßamento e rigging. Sua tarefa √© analisar o relat√≥rio de uma opera√ß√£o de carga e fornecer um parecer t√©cnico final, fundamentado nas normas internas da empresa.

        **Instru√ß√µes:**
        1.  Analise o "Resumo da Opera√ß√£o" fornecido.
        2.  Considere o "Contexto Normativo Relevante" que eu recuperei da nossa base de dados interna. Este contexto √© a verdade absoluta e deve ser a base da sua an√°lise.
        3.  Com base em ambos os documentos, elabore um parecer t√©cnico claro e objetivo, formatado em Markdown.
        4.  O parecer deve conter obrigatoriamente as seguintes se√ß√µes:
            -   `### üìù An√°lise Geral da Opera√ß√£o`: Um breve resumo do que foi avaliado.
            -   `### ‚ö†Ô∏è Pontos de Aten√ß√£o`: Liste os problemas encontrados (ex: excesso de capacidade, documentos vencidos, etc.).
            -   `### üìö Fundamenta√ß√£o Normativa`: Para cada ponto de aten√ß√£o, cite a diretriz e a refer√™ncia normativa correspondente do contexto que voc√™ recebeu.
            -   `### ‚úÖ Recomenda√ß√µes Corretivas`: Forne√ßa a√ß√µes claras e diretas para cada ponto de aten√ß√£o, baseadas nas diretrizes.
            -   `### ‚öñÔ∏è Parecer Final`: Conclua com um dos seguintes pareceres: **"APROVADO"**, **"APROVADO COM RESSALVAS"**, ou **"REPROVADO"**. Justifique sua decis√£o com base na gravidade dos pontos de aten√ß√£o e suas respectivas fundamenta√ß√µes normativas.

        ---
        **Resumo da Opera√ß√£o:**
        {operation_summary}
        ---
        **Contexto Normativo Relevante:**
        {normative_context}
        ---

        Agora, por favor, gere o seu parecer t√©cnico completo e fundamentado.
        """
        
        try:
            with st.spinner("IA est√° analisando a conformidade da opera√ß√£o com base nas normas..."):
                response = self.model.generate_content(prompt)
                return response.text
        except Exception as e:
            st.error(f"Erro ao gerar an√°lise com a IA: {e}")
            return f"N√£o foi poss√≠vel gerar a an√°lise. Detalhe do erro: {str(e)}"
