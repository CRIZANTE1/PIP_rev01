import streamlit as st
import pandas as pd
import numpy as np
import google.generativeai as genai
import gspread
from google.oauth2.service_account import Credentials

from AI.api_load import configure_google_api
from gdrive.config import get_credentials_dict
from gdrive.gdrive_upload import GoogleDriveUploader # <--- ADICIONE ESTA IMPORTA√á√ÉO

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

@st.cache_resource
def configure_google_api():
    """
    Carrega a chave API e configura a biblioteca do Google.
    Retorna True se bem-sucedido, False caso contr√°rio.
    """
    try:
        api_key = st.secrets.general.GOOGLE_API_KEY
        logging.info("Chave de API do Google encontrada nos secrets do Streamlit.")
    except (AttributeError, KeyError):
        st.error("ERRO CR√çTICO: GOOGLE_API_KEY n√£o encontrada em st.secrets.general.")
        return False
    
    if not api_key:
        st.error("ERRO CR√çTICO: A GOOGLE_API_KEY est√° vazia nos secrets.")
        return False

    try:
        genai.configure(api_key=api_key)
        logging.info("API do Google Generative AI configurada com sucesso.")
        return True
    except Exception as e:
        st.error(f"Erro ao configurar a API do Google: {str(e)}")
        return False

@st.cache_resource(ttl=3600)
def load_and_embed_rag_base() -> tuple[pd.DataFrame, np.ndarray | None]:
    """
    Carrega a planilha RAG, gera embeddings para cada chunk e armazena em cache.
    """
    # 1. Garante que a API Generativa do Google esteja configurada (para embeddings)
    if not configure_google_api():
        st.error("A API Generativa n√£o p√¥de ser configurada. A base de conhecimento n√£o ser√° carregada.")
        return pd.DataFrame(), None
        
    try:
        sheet_id = st.secrets.rag_config.sheet_id
    except (AttributeError, KeyError):
        st.error("Erro de configura√ß√£o: A chave 'sheet_id' n√£o foi encontrada na se√ß√£o [rag_config] dos secrets.")
        return pd.DataFrame(), None

    try:
        # 2. Carrega os dados da planilha usando gspread com credenciais expl√≠citas
        st.info("Autenticando com a API do Google Sheets...")
        # Escopo necess√°rio para ler planilhas
        scopes = ["https://www.googleapis.com/auth/spreadsheets.readonly"]
        creds_dict = get_credentials_dict()
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)
        
        # Autoriza o cliente gspread com as credenciais
        gc = gspread.authorize(creds)
        
        st.info(f"Acessando a planilha com ID: {sheet_id}...")
        spreadsheet = gc.open_by_key(sheet_id)
        worksheet = spreadsheet.sheet1 
        df = pd.DataFrame(worksheet.get_all_records())

        if df.empty or "Answer_Chunk" not in df.columns:
            st.error("A planilha RAG est√° vazia ou n√£o cont√©m a coluna 'Answer_Chunk'.")
            return pd.DataFrame(), None

        # 3. Gera os embeddings
        with st.spinner(f"Indexando a base de conhecimento ({len(df)} itens)..."):
            chunks_to_embed = df["Answer_Chunk"].astype(str).tolist()
            result = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=chunks_to_embed,
                task_type="RETRIEVAL_DOCUMENT",
                title="Normas de Seguran√ßa para I√ßamento de Carga"
            )
            embeddings = np.array(result['embedding'])
        
        st.success("Base de conhecimento indexada e pronta para uso!")
        return df, embeddings

    except gspread.exceptions.SpreadsheetNotFound:
        st.error(f"ERRO: A planilha com o ID '{sheet_id}' n√£o foi encontrada. Verifique se o ID est√° correto nos secrets e se a conta de servi√ßo ({creds_dict.get('client_email')}) tem permiss√£o para acess√°-la.")
        return pd.DataFrame(), None
    except Exception as e:
        # Captura o erro 403 aqui e d√° uma mensagem mais clara
        if "PERMISSION_DENIED" in str(e) or "403" in str(e):
             st.error(f"ERRO DE PERMISS√ÉO (403): A API do Google Sheets negou o acesso. Verifique se a 'Google Sheets API' est√° habilitada no seu projeto do Google Cloud e se a conta de servi√ßo ({creds_dict.get('client_email')}) foi compartilhada com a planilha.")
        else:
            st.error(f"Falha ao carregar ou processar a base de conhecimento: {e}")
        return pd.DataFrame(), None


class RAGAnalyzer:
    def __init__(self):
        # O __init__ agora √© extremamente leve, apenas chama a fun√ß√£o em cache
        self.rag_df, self.rag_embeddings = load_and_embed_rag_base()
        
        # Garante que o modelo de gera√ß√£o seja inicializado apenas se a API estiver configurada
        if configure_google_api():
            self.model = genai.GenerativeModel('gemini-1.5-flash-latest')
        else:
            self.model = None

    def _find_best_passages(self, query: str, top_k=3) -> pd.DataFrame:
        """Encontra os trechos mais relevantes usando a busca por similaridade."""
        if self.rag_df.empty or self.rag_embeddings is None or self.model is None:
            return pd.DataFrame()
        
        try:
            query_embedding = genai.embed_content(
                model=EMBEDDING_MODEL,
                content=query,
                task_type="RETRIEVAL_QUERY"
            )['embedding']
            
            # Calcula a similaridade (produto escalar)
            dot_products = np.dot(self.rag_embeddings, query_embedding)
            
            # Pega os √≠ndices dos 'top_k' melhores resultados
            indices = np.argsort(dot_products)[-top_k:][::-1]
            
            return self.rag_df.iloc[indices]
        except Exception as e:
            st.error(f"Erro durante a busca por similaridade: {e}")
            return pd.DataFrame()

    def _retrieve_context(self, issues: list) -> str:
        """Constr√≥i o prompt de contexto com base nos melhores trechos encontrados."""
        if self.rag_df.empty:
            return "A base de conhecimento normativo n√£o est√° dispon√≠vel ou falhou ao carregar."
        
        full_query = ". ".join(issues).replace("_", " ")
        context_str = "Contexto Normativo Relevante Encontrado:\n\n"
        
        relevant_df = self._find_best_passages(full_query)
        
        if relevant_df.empty:
            return "Nenhuma norma espec√≠fica encontrada na base de conhecimento para os pontos de aten√ß√£o desta opera√ß√£o."
        
        for _, row in relevant_df.iterrows():
            context_str += f"**Refer√™ncia:** {row.get('Norma_Referencia', 'N/A')} (Se√ß√£o: {row.get('Section_Number', 'N/A')})\n"
            context_str += f"**Pergunta Chave:** {row.get('Question', 'N/A')}\n"
            context_str += f"**Diretriz:** {row.get('Answer_Chunk', 'N/A')}\n"
            context_str += "---\n"
            
        return context_str

    def generate_final_analysis(self, operation_summary: str, issues: list) -> str:
        """Gera a an√°lise final (o prompt permanece o mesmo, mas agora recebe um contexto mais rico)."""
        
        if not issues:
             return "### ‚úÖ Parecer Final: APROVADO\n\nNenhum ponto de aten√ß√£o cr√≠tico foi identificado nos dados fornecidos. A opera√ß√£o parece estar em conformidade com os par√¢metros b√°sicos de seguran√ßa e documenta√ß√£o."

        normative_context = self._retrieve_context(issues)
        
        # O prompt permanece o mesmo, pois √© robusto e gen√©rico
        prompt = f"""
        **Persona:** Voc√™ √© um Profissional de Seguran√ßa do Trabalho altamente experiente, especialista em opera√ß√µes de i√ßamento e rigging. Sua tarefa √© analisar o relat√≥rio de uma opera√ß√£o de carga e fornecer um parecer t√©cnico final, fundamentado nas normas internas da empresa.

        **Instru√ß√µes:**
        1.  Analise o "Resumo da Opera√ß√£o" fornecido.
        2.  Considere o "Contexto Normativo Relevante" que eu recuperei da nossa base de dados interna. Este contexto √© a verdade absoluta e deve ser a base da sua an√°lise.
        3.  Com base em ambos os documentos, elabore um parecer t√©cnico claro e objetivo, formatado em Markdown.
        4.  O parecer deve conter obrigatoriamente as seguintes se√ß√µes:
            -   `### üìù An√°lise Geral da Opera√ß√£o`: Um breve resumo do que foi avaliado.
            -   `### ‚ö†Ô∏è Pontos de Aten√ß√£o`: Liste os problemas encontrados (ex: excesso de capacidade, documentos vencidos, etc.).
            -   `### üìö Fundamenta√ß√£o Normativa`: Para cada ponto de aten√ß√£o, cite a refer√™ncia normativa correspondente do contexto que voc√™ recebeu.
            -   `### ‚úÖ Recomenda√ß√µes Corretivas`: Forne√ßa a√ß√µes claras e diretas para cada ponto de aten√ß√£o, baseadas nas diretrizes.
            -   `### ‚öñÔ∏è Parecer Final`: Conclua com um dos seguintes pareceres: **"APROVADO"**, **"APROVADO COM RESSALVAS"**, ou **"REPROVADO"**. Justifique sua decis√£o com base na gravidade dos pontos de aten√ß√£o e suas respectivas fundamenta√ß√µes normativas.

        ---
        **Resumo da Opera√ß√£o:**
        {operation_summary}
        ---
        **Contexto Normativo Relevante:**
        {normative_context}
        ---

        Agora, por favor, gere o seu parecer t√©cnico completo e fundamentado.
        """
        
        try:
            with st.spinner("IA est√° analisando a conformidade da opera√ß√£o com base nas normas..."):
                response = self.model.generate_content(prompt)
                return response.text
        except Exception as e:
            st.error(f"Erro ao gerar an√°lise com a IA: {e}")
            return f"N√£o foi poss√≠vel gerar a an√°lise. Detalhe do erro: {str(e)}"
